<!DOCTYPE html>
<html>
    <head>
  
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width,initial-scale=1">
<title>Challanges</title>
    </head>
    <body background="http://nexttechmag.com/wp-content/uploads/2021/03/AI-CAREER.jpg">
        <h1>Challanges</h1>
        <li><a href="AI  Home Page.html">Home page</a></li>
<li><a href="parts of a series of AI.html">Series of AI </a></li>
<li><a href="challanges.html">Challanges of AI</a></li>
<li><a href="Benefits&Risks ofAI.html">Benefits &Risks of AI</a></li>

<p><a href="/wiki/Knowledge_representation" class="mw-redirect" title="Knowledge representation">Knowledge representation</a><sup id="cite_ref-Knowledge_representation_104-0" class="reference"><a href="#cite_note-Knowledge_representation-104">[101]</a></sup> and <a href="/wiki/Knowledge_engineering" title="Knowledge engineering">knowledge engineering</a><sup id="cite_ref-Knowledge_engineering_105-0" class="reference"><a href="#cite_note-Knowledge_engineering-105">[102]</a></sup> are central to classical AI research. Some "expert systems" attempt to gather explicit knowledge possessed by experts in some narrow domain. In addition, some projects attempt to gather the "commonsense knowledge" known to the average person into a database containing extensive knowledge about the world. Among the things a comprehensive commonsense knowledge base would contain are: objects, properties, categories and relations between objects;<sup id="cite_ref-Representing_categories_and_relations_106-0" class="reference"><a href="#cite_note-Representing_categories_and_relations-106">[103]</a></sup> situations, events, states and time;<sup id="cite_ref-Representing_time_107-0" class="reference"><a href="#cite_note-Representing_time-107">[104]</a></sup> causes and effects;<sup id="cite_ref-Representing_causation_108-0" class="reference"><a href="#cite_note-Representing_causation-108">[105]</a></sup> knowledge about knowledge (what we know about what other people know);<sup id="cite_ref-Representing_knowledge_about_knowledge_109-0" class="reference"><a href="#cite_note-Representing_knowledge_about_knowledge-109">[106]</a></sup> and many other, less well researched domains. A representation of "what exists" is an <a href="/wiki/Ontology_(computer_science)" class="mw-redirect" title="Ontology (computer science)">ontology</a>: the set of objects, relations, concepts, and properties formally described so that software agents can interpret them. The <a href="/wiki/Semantics" title="Semantics">semantics</a> of these are captured as <a href="/wiki/Description_logic" title="Description logic">description logic</a> concepts, roles, and individuals, and typically implemented as classes, properties, and individuals in the <a href="/wiki/Web_Ontology_Language" title="Web Ontology Language">Web Ontology Language</a>.<sup id="cite_ref-110" class="reference"><a href="#cite_note-110">[107]</a></sup> The most general ontologies are called <a href="/wiki/Upper_ontology" title="Upper ontology">upper ontologies</a>, which attempt to provide a foundation for all other knowledge<sup id="cite_ref-Ontology_111-0" class="reference"><a href="#cite_note-Ontology-111">[108]</a></sup> by acting as mediators between <a href="/wiki/Domain_ontology" class="mw-redirect" title="Domain ontology">domain ontologies</a> that cover specific knowledge about a particular knowledge domain (field of interest or area of concern). Such formal knowledge representations can be used in content-based indexing and retrieval,<sup id="cite_ref-112" class="reference"><a href="#cite_note-112">[109]</a></sup> scene interpretation,<sup id="cite_ref-113" class="reference"><a href="#cite_note-113">[110]</a></sup> clinical decision support,<sup id="cite_ref-114" class="reference"><a href="#cite_note-114">[111]</a></sup> knowledge discovery (mining "interesting" and actionable inferences from large databases),<sup id="cite_ref-115" class="reference"><a href="#cite_note-115">[112]</a></sup> and other areas.<sup id="cite_ref-116" class="reference"><a href="#cite_note-116">[113]</a></sup>
</p>
<img alt="" src="//upload.wikimedia.org/wikipedia/commons/thumb/9/9e/GFO_taxonomy_tree.png/220px-GFO_taxonomy_tree.png" decoding="async" width="220" height="208" class="thumbimage" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/9/9e/GFO_taxonomy_tree.png/330px-GFO_taxonomy_tree.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/9/9e/GFO_taxonomy_tree.png/440px-GFO_taxonomy_tree.png 2x" data-file-width="469" data-file-height="443">
<p><a href="/wiki/Knowledge_representation" class="mw-redirect" title="Knowledge representation">Knowledge representation</a><sup id="cite_ref-Knowledge_representation_104-0" class="reference"><a href="#cite_note-Knowledge_representation-104">[101]</a></sup> and <a href="/wiki/Knowledge_engineering" title="Knowledge engineering">knowledge engineering</a><sup id="cite_ref-Knowledge_engineering_105-0" class="reference"><a href="#cite_note-Knowledge_engineering-105">[102]</a></sup> are central to classical AI research. Some "expert systems" attempt to gather explicit knowledge possessed by experts in some narrow domain. In addition, some projects attempt to gather the "commonsense knowledge" known to the average person into a database containing extensive knowledge about the world. Among the things a comprehensive commonsense knowledge base would contain are: objects, properties, categories and relations between objects;<sup id="cite_ref-Representing_categories_and_relations_106-0" class="reference"><a href="#cite_note-Representing_categories_and_relations-106">[103]</a></sup> situations, events, states and time;<sup id="cite_ref-Representing_time_107-0" class="reference"><a href="#cite_note-Representing_time-107">[104]</a></sup> causes and effects;<sup id="cite_ref-Representing_causation_108-0" class="reference"><a href="#cite_note-Representing_causation-108">[105]</a></sup> knowledge about knowledge (what we know about what other people know);<sup id="cite_ref-Representing_knowledge_about_knowledge_109-0" class="reference"><a href="#cite_note-Representing_knowledge_about_knowledge-109">[106]</a></sup> and many other, less well researched domains. A representation of "what exists" is an <a href="/wiki/Ontology_(computer_science)" class="mw-redirect" title="Ontology (computer science)">ontology</a>: the set of objects, relations, concepts, and properties formally described so that software agents can interpret them. The <a href="/wiki/Semantics" title="Semantics">semantics</a> of these are captured as <a href="/wiki/Description_logic" title="Description logic">description logic</a> concepts, roles, and individuals, and typically implemented as classes, properties, and individuals in the <a href="/wiki/Web_Ontology_Language" title="Web Ontology Language">Web Ontology Language</a>.<sup id="cite_ref-110" class="reference"><a href="#cite_note-110">[107]</a></sup> The most general ontologies are called <a href="/wiki/Upper_ontology" title="Upper ontology">upper ontologies</a>, which attempt to provide a foundation for all other knowledge<sup id="cite_ref-Ontology_111-0" class="reference"><a href="#cite_note-Ontology-111">[108]</a></sup> by acting as mediators between <a href="/wiki/Domain_ontology" class="mw-redirect" title="Domain ontology">domain ontologies</a> that cover specific knowledge about a particular knowledge domain (field of interest or area of concern). Such formal knowledge representations can be used in content-based indexing and retrieval,<sup id="cite_ref-112" class="reference"><a href="#cite_note-112">[109]</a></sup> scene interpretation,<sup id="cite_ref-113" class="reference"><a href="#cite_note-113">[110]</a></sup> clinical decision support,<sup id="cite_ref-114" class="reference"><a href="#cite_note-114">[111]</a></sup> knowledge discovery (mining "interesting" and actionable inferences from large databases),<sup id="cite_ref-115" class="reference"><a href="#cite_note-115">[112]</a></sup> and other areas.<sup id="cite_ref-116" class="reference"><a href="#cite_note-116">[113]</a></sup>
</p>
<dl><dt><a href="/wiki/Default_reasoning" class="mw-redirect" title="Default reasoning">Default reasoning</a> and the <a href="/wiki/Qualification_problem" title="Description logic">qualification problem</a></dt>
    <dd>Many of the things people know take the form of "working assumptions". For example, if a bird comes up in conversation, people typically picture a fist-sized animal that sings and flies. None of these things are true about all birds. <a href="/wiki/John_McCarthy_(computer_scientist)" title="John McCarthy (computer scientist)">John McCarthy</a> identified this problem in 1969<sup id="cite_ref-Qualification_problem_117-0" class="reference"><a href="#cite_note-Qualification_problem-117">[114]</a></sup> as the qualification problem: for any commonsense rule that AI researchers care to represent, there tend to be a huge number of exceptions. Almost nothing is simply true or false in the way that abstract logic requires. AI research has explored a number of solutions to this problem.<sup id="cite_ref-Default_reasoning_and_non-monotonic_logic_118-0" class="reference"><a href="#cite_note-Default_reasoning_and_non-monotonic_logic-118">[115]</a></sup></dd>
    <dt>Breadth of commonsense knowledge</dt>
    <dd>The number of atomic facts that the average person knows is very large. Research projects that attempt to build a complete knowledge base of <a href="/wiki/Commonsense_knowledge" class="mw-redirect" title="Commonsense knowledge">commonsense knowledge</a> (e.g., <a href="/wiki/Cyc" title="Cyc">Cyc</a>) require enormous amounts of laborious <a href="/wiki/Ontology_engineering" title="Ontology engineering">ontological engineering</a>â€”they must be built, by hand, one complicated concept at a time.<sup id="cite_ref-Breadth_of_commonsense_knowledge_119-0" class="reference"><a href="#cite_note-Breadth_of_commonsense_knowledge-119">[116]</a></sup></dd>
    <dt>Subsymbolic form of some commonsense knowledge</dt>
    <dd>Much of what people know is not represented as "facts" or "statements" that they could express verbally. For example, a chess master will avoid a particular chess position because it "feels too exposed"<sup id="cite_ref-FOOTNOTEDreyfusDreyfus1986_120-0" class="reference"><a href="#cite_note-FOOTNOTEDreyfusDreyfus1986-120">[117]</a></sup> or an art critic can take one look at a statue and realize that it is a fake.<sup id="cite_ref-FOOTNOTEGladwell2005_121-0" class="reference"><a href="#cite_note-FOOTNOTEGladwell2005-121">[118]</a></sup> These are non-conscious and sub-symbolic intuitions or tendencies in the human brain.<sup id="cite_ref-Intuition_122-0" class="reference"><a href="#cite_note-Intuition-122">[119]</a></sup> Knowledge like this informs, supports and provides a context for symbolic, conscious knowledge. As with the related problem of sub-symbolic reasoning, it is hoped that <a href="/wiki/Situated_artificial_intelligence" class="mw-redirect" title="Situated artificial intelligence">situated AI</a>, <a href="/wiki/Computational_intelligence" title="Computational intelligence">computational intelligence</a>, or <a href="#Statistical">statistical AI</a> will provide ways to represent this knowledge.<sup id="cite_ref-Intuition_122-1" class="reference"><a href="#cite_note-Intuition-122">[119]</a></sup></dd></dl>
    <dd>Much of what people know is not represented as "facts" or "statements" that they could express verbally. For example, a chess master will avoid a particular chess position because it "feels too exposed"<sup id="cite_ref-FOOTNOTEDreyfusDreyfus1986_120-0" class="reference"><a href="#cite_note-FOOTNOTEDreyfusDreyfus1986-120">[117]</a></sup> or an art critic can take one look at a statue and realize that it is a fake.<sup id="cite_ref-FOOTNOTEGladwell2005_121-0" class="reference"><a href="#cite_note-FOOTNOTEGladwell2005-121">[118]</a></sup> These are non-conscious and sub-symbolic intuitions or tendencies in the human brain.<sup id="cite_ref-Intuition_122-0" class="reference"><a href="#cite_note-Intuition-122">[119]</a></sup> Knowledge like this informs, supports and provides a context for symbolic, conscious knowledge. As with the related problem of sub-symbolic reasoning, it is hoped that <a href="/wiki/Situated_artificial_intelligence" class="mw-redirect" title="Situated artificial intelligence">situated AI</a>, <a href="/wiki/Computational_intelligence" title="Computational intelligence">computational intelligence</a>, or <a href="#Statistical">statistical AI</a> will provide ways to represent this knowledge.<sup id="cite_ref-Intuition_122-1" class="reference"><a href="#cite_note-Intuition-122">[119]</a></sup></dd>
    <a href="/wiki/Automated_planning_and_scheduling" title="Ontology engineering">Automated planning and scheduling</a>
    <p>Intelligent agents must be able to set goals and achieve them.<sup id="cite_ref-Planning_123-0" class="reference"><a href="#cite_note-Planning-123">[120]</a></sup> They need a way to visualize the futureâ€”a representation of the state of the world and be able to make predictions about how their actions will change itâ€”and be able to make choices that maximize the <a href="/wiki/Utility" title="Utility">utility</a> (or "value") of available choices.<sup id="cite_ref-Information_value_theory_124-0" class="reference"><a href="#cite_note-Information_value_theory-124">[121]</a></sup>
    </p>
    <img alt="" src="//upload.wikimedia.org/wikipedia/commons/thumb/7/76/Hierarchical-control-system.svg/220px-Hierarchical-control-system.svg.png" decoding="async" width="220" height="199" class="thumbimage" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/7/76/Hierarchical-control-system.svg/330px-Hierarchical-control-system.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/7/76/Hierarchical-control-system.svg/440px-Hierarchical-control-system.svg.png 2x" data-file-width="596" data-file-height="539">
    <p>In classical planning problems, the agent can assume that it is the only system acting in the world, allowing the agent to be certain of the consequences of its actions.<sup id="cite_ref-Classical_planning_125-0" class="reference"><a href="#cite_note-Classical_planning-125">[122]</a></sup> However, if the agent is not the only actor, then it requires that the agent can reason under uncertainty. This calls for an agent that can not only assess its environment and make predictions but also evaluate its predictions and adapt based on its assessment.<sup id="cite_ref-Non-deterministic_planning_126-0" class="reference"><a href="#cite_note-Non-deterministic_planning-126">[123]</a></sup>
    </p>
    <p><a href="/wiki/Multi-agent_planning" title="Multi-agent planning">Multi-agent planning</a> uses the <a href="/wiki/Cooperation" title="Cooperation">cooperation</a> and competition of many agents to achieve a given goal. <a href="/wiki/Emergent_behavior" class="mw-redirect" title="Emergent behavior">Emergent behavior</a> such as this is used by <a href="/wiki/Evolutionary_algorithms" class="mw-redirect" title="Evolutionary algorithms">evolutionary algorithms</a> and <a href="/wiki/Swarm_intelligence" title="Swarm intelligence">swarm intelligence</a>.<sup id="cite_ref-Multi-agent_planning_127-0" class="reference"><a href="#cite_note-Multi-agent_planning-127">[124]</a></sup>
    </p>
    <h3><span class="mw-headline" id="Learning">Learning</span></h3>
    <div class="thumb tright"><div class="thumbinner" style="width:222px;"><a href="/wiki/File:Joseph_Ayerle_portrait_of_Ornella_Muti_(detail),_calculated_by_Artificial_Intelligence_(AI)_technology.jpg" class="image"><img alt="" src="//upload.wikimedia.org/wikipedia/commons/thumb/1/13/Joseph_Ayerle_portrait_of_Ornella_Muti_%28detail%29%2C_calculated_by_Artificial_Intelligence_%28AI%29_technology.jpg/220px-Joseph_Ayerle_portrait_of_Ornella_Muti_%28detail%29%2C_calculated_by_Artificial_Intelligence_%28AI%29_technology.jpg" decoding="async" width="220" height="255" class="thumbimage" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/1/13/Joseph_Ayerle_portrait_of_Ornella_Muti_%28detail%29%2C_calculated_by_Artificial_Intelligence_%28AI%29_technology.jpg/330px-Joseph_Ayerle_portrait_of_Ornella_Muti_%28detail%29%2C_calculated_by_Artificial_Intelligence_%28AI%29_technology.jpg 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/1/13/Joseph_Ayerle_portrait_of_Ornella_Muti_%28detail%29%2C_calculated_by_Artificial_Intelligence_%28AI%29_technology.jpg/440px-Joseph_Ayerle_portrait_of_Ornella_Muti_%28detail%29%2C_calculated_by_Artificial_Intelligence_%28AI%29_technology.jpg 2x" data-file-width="1726" data-file-height="2000"></a>  <div class="thumbcaption"><div class="magnify"><a href="/wiki/File:Joseph_Ayerle_portrait_of_Ornella_Muti_(detail),_calculated_by_Artificial_Intelligence_(AI)_technology.jpg" class="internal" title="Enlarge"></a></div>For this project the AI had to find the typical patterns in the colors and brushstrokes of Renaissance painter <a href="/wiki/Raphael" title="Raphael">Raphael</a>. The portrait  shows the face of the actress <a href="/wiki/Ornella_Muti" title="Ornella Muti">Ornella Muti</a>, "painted" by AI in the style of Raphael.</div></div></div>
    <p>Machine learning (ML), a fundamental concept of AI research since the field's inception,<sup id="cite_ref-130" class="reference"><a href="#cite_note-130">[d]</a></sup> is the study of computer algorithms that improve automatically through experience.<sup id="cite_ref-131" class="reference"><a href="#cite_note-131">[e]</a></sup><sup id="cite_ref-Machine_learning_132-0" class="reference"><a href="#cite_note-Machine_learning-132">[127]</a></sup>
    </p>
    <p><a href="/wiki/Unsupervised_learning" title="Unsupervised learning">Unsupervised learning</a> is the ability to find patterns in a stream of input, without requiring a human to label the inputs first. <a href="/wiki/Supervised_learning" title="Supervised learning">Supervised learning</a> includes both <a href="/wiki/Statistical_classification" title="Statistical classification">classification</a> and numerical <a href="/wiki/Regression_analysis" title="Regression analysis">regression</a>, which requires a human to label the input data first. Classification is used to determine what category something belongs in, and occurs after a program sees a number of examples of things from several categories. Regression is the attempt to produce a function that describes the relationship between inputs and outputs and predicts how the outputs should change as the inputs change.<sup id="cite_ref-Machine_learning_132-1" class="reference"><a href="#cite_note-Machine_learning-132">[127]</a></sup> Both classifiers and regression learners can be viewed as "function approximators" trying to learn an unknown (possibly implicit) function; for example, a spam classifier can be viewed as learning a function that maps from the text of an email to one of two categories, "spam" or "not spam". <a href="/wiki/Computational_learning_theory" title="Computational learning theory">Computational learning theory</a> can assess learners by <a href="/wiki/Computational_complexity" title="Computational complexity">computational complexity</a>, by <a href="/wiki/Sample_complexity" title="Sample complexity">sample complexity</a> (how much data is required), or by other notions of <a href="/wiki/Optimization_theory" class="mw-redirect" title="Optimization theory">optimization</a>.<sup id="cite_ref-133" class="reference"><a href="#cite_note-133">[128]</a></sup> In <a href="/wiki/Reinforcement_learning" title="Reinforcement learning">reinforcement learning</a><sup id="cite_ref-Reinforcement_learning_134-0" class="reference"><a href="#cite_note-Reinforcement_learning-134">[129]</a></sup> the agent is rewarded for good responses and punished for bad ones. The agent uses this sequence of rewards and punishments to form a strategy for operating in its problem space.
</p>
<h3><span class="mw-headline" id="Natural_language_processing">Natural language processing</span></h3>
<div class="thumb tright"><div class="thumbinner" style="width:222px;"><a href="/wiki/File:ParseTree.svg" class="image"><img alt="" src="//upload.wikimedia.org/wikipedia/commons/thumb/6/6e/ParseTree.svg/220px-ParseTree.svg.png" decoding="async" width="220" height="220" class="thumbimage" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/6/6e/ParseTree.svg/330px-ParseTree.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/6/6e/ParseTree.svg/440px-ParseTree.svg.png 2x" data-file-width="120" data-file-height="120"></a>  <div class="thumbcaption"><div class="magnify"><a href="/wiki/File:ParseTree.svg" class="internal" title="Enlarge"></a></div>A <a href="/wiki/Parse_tree" title="Parse tree">parse tree</a> represents the <a href="/wiki/Syntax" title="Syntax">syntactic</a> structure of a sentence according to some <a href="/wiki/Formal_grammar" title="Formal grammar">formal grammar</a>.</div></div></div>
<p><a href="/wiki/Natural_language_processing" title="Natural language processing">Natural language processing</a><sup id="cite_ref-Natural_language_processing_135-0" class="reference"><a href="#cite_note-Natural_language_processing-135">[130]</a></sup> (NLP) allows machines to read and <a href="/wiki/Natural_language_understanding" class="mw-redirect" title="Natural language understanding">understand</a> human language. A sufficiently powerful natural language processing system would enable <a href="/wiki/Natural-language_user_interface" title="Natural-language user interface">natural-language user interfaces</a> and the acquisition of knowledge directly from human-written sources, such as newswire texts. Some straightforward applications of natural language processing include <a href="/wiki/Information_retrieval" title="Information retrieval">information retrieval</a>, <a href="/wiki/Text_mining" title="Text mining">text mining</a>, <a href="/wiki/Question_answering" title="Question answering">question answering</a> and <a href="/wiki/Machine_translation" title="Machine translation">machine translation</a>.<sup id="cite_ref-Applications_of_natural_language_processing_136-0" class="reference"><a href="#cite_note-Applications_of_natural_language_processing-136">[131]</a></sup> Many current approaches use word co-occurrence frequencies to construct syntactic representations of text. "Keyword spotting" strategies for search are popular and scalable but dumb; a search query for "dog" might only match documents with the literal word "dog" and miss a document with the word "poodle". "Lexical affinity" strategies use the occurrence of words such as "accident" to <a href="/wiki/Sentiment_analysis" title="Sentiment analysis">assess the sentiment</a> of a document. Modern statistical NLP approaches can combine all these strategies as well as others, and often achieve acceptable accuracy at the page or paragraph level. Beyond semantic NLP, the ultimate goal of "narrative" NLP is to embody a full understanding of commonsense reasoning.<sup id="cite_ref-137" class="reference"><a href="#cite_note-137">[132]</a></sup> By 2019, <a href="/wiki/Transformer_(machine_learning_model)" title="Transformer (machine learning model)">transformer</a>-based deep learning architectures could generate coherent text.<sup id="cite_ref-138" class="reference"><a href="#cite_note-138">[133]</a></sup>
</p>
<span class="mw-headline" id="Motion_and_manipulation">Motion and manipulation</span>
<p>AI is heavily used in robotics.<sup id="cite_ref-Robotics_143-0" class="reference"><a href="#cite_note-Robotics-143">[138]</a></sup> Advanced <a href="/wiki/Robotic_arm" title="Robotic arm">robotic arms</a> and other <a href="/wiki/Industrial_robot" title="Industrial robot">industrial robots</a>, widely used in modern factories, can learn from experience how to move efficiently despite the presence of friction and gear slippage.<sup id="cite_ref-Configuration_space_144-0" class="reference"><a href="#cite_note-Configuration_space-144">[139]</a></sup> A modern mobile robot, when given a small, static, and visible environment, can easily determine its location and <a href="/wiki/Robotic_mapping" title="Robotic mapping">map</a> its environment; however, dynamic environments, such as (in <a href="/wiki/Endoscopy" title="Endoscopy">endoscopy</a>) the interior of a patient's breathing body, pose a greater challenge. <a href="/wiki/Motion_planning" title="Motion planning">Motion planning</a> is the process of breaking down a movement task into "primitives" such as individual joint movements. Such movement often involves compliant motion, a process where movement requires maintaining physical contact with an object.<sup id="cite_ref-FOOTNOTETecuci2012_145-0" class="reference"><a href="#cite_note-FOOTNOTETecuci2012-145">[140]</a></sup><sup id="cite_ref-Robotic_mapping_146-0" class="reference"><a href="#cite_note-Robotic_mapping-146">[141]</a></sup><sup id="cite_ref-147" class="reference"><a href="#cite_note-147">[142]</a></sup> <a href="/wiki/Moravec%27s_paradox" title="Moravec's paradox">Moravec's paradox</a> generalizes that low-level sensorimotor skills that humans take for granted are, counterintuitively, difficult to program into a robot; the paradox is named after <a href="/wiki/Hans_Moravec" title="Hans Moravec">Hans Moravec</a>, who stated in 1988 that "it is comparatively easy to make computers exhibit adult level performance on intelligence tests or playing checkers, and difficult or impossible to give them the skills of a one-year-old when it comes to perception and mobility".<sup id="cite_ref-FOOTNOTEMoravec198815_148-0" class="reference"><a href="#cite_note-FOOTNOTEMoravec198815-148">[143]</a></sup><sup id="cite_ref-149" class="reference"><a href="#cite_note-149">[144]</a></sup> This is attributed to the fact that, unlike checkers, physical dexterity has been a direct target of <a href="/wiki/Natural_selection" title="Natural selection">natural selection</a> for millions of years.<sup id="cite_ref-150" class="reference"><a href="#cite_note-150">[145]</a></sup>
</p>
<h3><span class="mw-headline" id="Social_intelligence">Social intelligence</span></h3>
<div class="thumb tright"><div class="thumbinner" style="width:222px;"><a href="/wiki/File:Kismet_robot_at_MIT_Museum.jpg" class="image"><img alt="" src="//upload.wikimedia.org/wikipedia/commons/thumb/b/b8/Kismet_robot_at_MIT_Museum.jpg/220px-Kismet_robot_at_MIT_Museum.jpg" decoding="async" width="220" height="165" class="thumbimage" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/b/b8/Kismet_robot_at_MIT_Museum.jpg/330px-Kismet_robot_at_MIT_Museum.jpg 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/b/b8/Kismet_robot_at_MIT_Museum.jpg/440px-Kismet_robot_at_MIT_Museum.jpg 2x" data-file-width="2272" data-file-height="1704"></a>  <div class="thumbcaption"><div class="magnify"><a href="/wiki/File:Kismet_robot_at_MIT_Museum.jpg" class="internal" title="Enlarge"></a></div><a href="/wiki/Kismet_(robot)" title="Kismet (robot)">Kismet</a>, a robot with rudimentary social skills<sup id="cite_ref-Kismet_151-0" class="reference"><a href="#cite_note-Kismet-151">[146]</a></sup></div></div></div>
<p>Moravec's paradox can be extended to many forms of social intelligence.<sup id="cite_ref-152" class="reference"><a href="#cite_note-152">[147]</a></sup><sup id="cite_ref-153" class="reference"><a href="#cite_note-153">[148]</a></sup> Distributed multi-agent coordination of autonomous vehicles remains a difficult problem.<sup id="cite_ref-154" class="reference"><a href="#cite_note-154">[149]</a></sup> <a href="/wiki/Affective_computing" title="Affective computing">Affective computing</a> is an interdisciplinary umbrella that comprises systems which recognize, interpret, process, or simulate human <a href="/wiki/Affect_(psychology)" title="Affect (psychology)">affects</a>.<sup id="cite_ref-FOOTNOTEThro1993_155-0" class="reference"><a href="#cite_note-FOOTNOTEThro1993-155">[150]</a></sup><sup id="cite_ref-FOOTNOTEEdelson1991_156-0" class="reference"><a href="#cite_note-FOOTNOTEEdelson1991-156">[151]</a></sup><sup id="cite_ref-FOOTNOTETaoTan2005_157-0" class="reference"><a href="#cite_note-FOOTNOTETaoTan2005-157">[152]</a></sup> Moderate successes related to affective computing include textual <a href="/wiki/Sentiment_analysis" title="Sentiment analysis">sentiment analysis</a> and, more recently, multimodal affect analysis (see <a href="/wiki/Multimodal_sentiment_analysis" title="Multimodal sentiment analysis">multimodal sentiment analysis</a>), wherein AI classifies the affects displayed by a videotaped subject.<sup id="cite_ref-158" class="reference"><a href="#cite_note-158">[153]</a></sup>
</p>
<p>In the long run, social skills and an understanding of human emotion and <a href="/wiki/Game_theory" title="Game theory">game theory</a> would be valuable to a social agent. The ability to predict the actions of others by understanding their motives and emotional states would allow an agent to make better decisions. Some computer systems mimic human emotion and expressions to appear more sensitive to the emotional dynamics of human interaction, or to otherwise facilitate <a href="/wiki/Human%E2%80%93computer_interaction" title="Humanâ€“computer interaction">humanâ€“computer interaction</a>.<sup id="cite_ref-Emotion_and_affective_computing_159-0" class="reference"><a href="#cite_note-Emotion_and_affective_computing-159">[154]</a></sup> Similarly, some <a href="/wiki/Virtual_assistant" title="Virtual assistant">virtual assistants</a> are programmed to speak conversationally or even to banter humorously; this tends to give naÃ¯ve users an unrealistic conception of how intelligent existing computer agents actually are.<sup id="cite_ref-160" class="reference"><a href="#cite_note-160">[155]</a></sup>
</p>
<h3><span class="mw-headline" id="General_intelligence">General intelligence</span></h3>
<p>Historically, projects such as the Cyc knowledge base (1984â€“) and the massive Japanese <a href="/wiki/Fifth_generation_computer" title="Fifth generation computer">Fifth Generation Computer Systems</a> initiative (1982â€“1992) attempted to cover the breadth of human cognition. These early projects failed to escape the limitations of non-quantitative symbolic logic models and, in retrospect, greatly underestimated the difficulty of cross-domain AI. Nowadays, most current AI researchers work instead on tractable "narrow AI" applications (such as medical diagnosis or automobile navigation).<sup id="cite_ref-161" class="reference"><a href="#cite_note-161">[156]</a></sup> Many researchers predict that such "narrow AI" work in different individual domains will eventually be incorporated into a machine with <a href="/wiki/Artificial_general_intelligence" title="Artificial general intelligence">artificial general intelligence</a> (AGI), combining most of the narrow skills mentioned in this article and at some point even exceeding human ability in most or all these areas.<sup id="cite_ref-General_intelligence_26-1" class="reference"><a href="#cite_note-General_intelligence-26">[26]</a></sup><sup id="cite_ref-Roberts_162-0" class="reference"><a href="#cite_note-Roberts-162">[157]</a></sup> Many advances have general, cross-domain significance. One high-profile example is that <a href="/wiki/DeepMind" title="DeepMind">DeepMind</a> in the 2010s developed a "generalized artificial intelligence" that could learn many diverse <a href="/wiki/Atari_2600" title="Atari 2600">Atari</a> games on its own, and later developed a variant of the system which succeeds at <a href="/wiki/Catastrophic_interference#The_Sequential_Learning_Problem:_McCloskey_and_Cohen_(1989)" title="Catastrophic interference">sequential learning</a>.<sup id="cite_ref-163" class="reference"><a href="#cite_note-163">[158]</a></sup><sup id="cite_ref-164" class="reference"><a href="#cite_note-164">[159]</a></sup><sup id="cite_ref-165" class="reference"><a href="#cite_note-165">[160]</a></sup> Besides <a href="/wiki/Transfer_learning" title="Transfer learning">transfer learning</a>,<sup id="cite_ref-166" class="reference"><a href="#cite_note-166">[161]</a></sup> hypothetical AGI breakthroughs could include the development of reflective architectures that can engage in decision-theoretic metareasoning, and figuring out how to "slurp up" a comprehensive knowledge base from the entire unstructured <a href="/wiki/World_Wide_Web" title="World Wide Web">Web</a>.<sup id="cite_ref-FOOTNOTERussellNorvig2009Chapter_27._AI:_The_Present_and_Future_167-0" class="reference"><a href="#cite_note-FOOTNOTERussellNorvig2009Chapter_27._AI:_The_Present_and_Future-167">[162]</a></sup> Some argue that some kind of (currently-undiscovered) conceptually straightforward, but mathematically difficult, "Master Algorithm" could lead to AGI.<sup id="cite_ref-FOOTNOTEDomingos2015Chapter_9._The_Pieces_of_the_Puzzle_Fall_into_Place_168-0" class="reference"><a href="#cite_note-FOOTNOTEDomingos2015Chapter_9._The_Pieces_of_the_Puzzle_Fall_into_Place-168">[163]</a></sup> Finally, a few "emergent" approaches look to simulating human intelligence extremely closely, and believe that <a href="/wiki/Anthropomorphism" title="Anthropomorphism">anthropomorphic</a> features like an <a href="/wiki/Artificial_brain" title="Artificial brain">artificial brain</a> or simulated <a href="/wiki/Developmental_robotics" title="Developmental robotics">child development</a> may someday reach a critical point where general intelligence emerges.<sup id="cite_ref-Brain_simulation_169-0" class="reference"><a href="#cite_note-Brain_simulation-169">[164]</a></sup><sup id="cite_ref-170" class="reference"><a href="#cite_note-170">[165]</a></sup>
</p>
<p>Many of the problems in this article may also require general intelligence, if machines are to solve the problems as well as people do. For example, even specific straightforward tasks, like <a href="/wiki/Machine_translation" title="Machine translation">machine translation</a>, require that a machine read and write in both languages (<a href="#Natural_language_processing">NLP</a>), follow the author's argument (<a href="#Deduction,_reasoning,_problem_solving">reason</a>), know what is being talked about (<a href="#Knowledge_representation">knowledge</a>), and faithfully reproduce the author's original intent (<a href="#Social_intelligence">social intelligence</a>). A problem like machine translation is considered "<a href="/wiki/AI-complete" title="AI-complete">AI-complete</a>", because all of these problems need to be solved simultaneously in order to reach human-level machine performance.
</p>
<h2><span class="mw-headline" id="Approaches">Approaches</span></h2>
<p>No established unifying theory or <a href="/wiki/Paradigm" title="Paradigm">paradigm</a> guides AI research. Researchers disagree about many issues.<sup id="cite_ref-172" class="reference"><a href="#cite_note-172">[f]</a></sup> A few of the most long-standing questions that have remained unanswered are these: should artificial intelligence simulate natural intelligence by studying <a href="/wiki/Psychology" title="Psychology">psychology</a> or <a href="/wiki/Neuroscience" title="Neuroscience">neurobiology</a>? Or is <a href="/wiki/Human_biology" title="Human biology">human biology</a> as irrelevant to AI research as bird biology is to <a href="/wiki/Aeronautical_engineering" class="mw-redirect" title="Aeronautical engineering">aeronautical engineering</a>?<sup id="cite_ref-Biological_intelligence_vs._intelligence_in_general_23-1" class="reference"><a href="#cite_note-Biological_intelligence_vs._intelligence_in_general-23">[23]</a></sup>
    Can intelligent behavior be described using simple, elegant principles (such as <a href="/wiki/Logic" title="Logic">logic</a> or <a href="/wiki/Optimization_(mathematics)" class="mw-redirect" title="Optimization (mathematics)">optimization</a>)? Or does it necessarily require solving a large number of unrelated problems?<sup id="cite_ref-Neats_vs._scruffies_24-1" class="reference"><a href="#cite_note-Neats_vs._scruffies-24">[24]</a></sup>
    </p>
    <h3><span class="mw-headline" id="Cybernetics_and_brain_simulation">Cybernetics and brain simulation</span></h3>
    <p>In the 1940s and 1950s, a number of researchers explored the connection between <a href="/wiki/Neurobiology" class="mw-redirect" title="Neurobiology">neurobiology</a>, <a href="/wiki/Information_theory" title="Information theory">information theory</a>, and <a href="/wiki/Cybernetics" title="Cybernetics">cybernetics</a>. Some of them built machines that used electronic networks to exhibit rudimentary intelligence, such as <a href="/wiki/W._Grey_Walter" class="mw-redirect" title="W. Grey Walter">W. Grey Walter</a>'s <a href="/wiki/Turtle_(robot)" title="Turtle (robot)">turtles</a> and the <a href="/wiki/Johns_Hopkins_Beast" title="Johns Hopkins Beast">Johns Hopkins Beast</a>. Many of these researchers gathered for meetings of the Teleological Society at <a href="/wiki/Princeton_University" title="Princeton University">Princeton University</a> and the <a href="/wiki/Ratio_Club" title="Ratio Club">Ratio Club</a> in England.<sup id="cite_ref-AI's_immediate_precursors_173-0" class="reference"><a href="#cite_note-AI's_immediate_precursors-173">[167]</a></sup> By 1960, this approach was largely abandoned, although elements of it would be revived in the 1980s.
    </p>
    <h3><span class="mw-headline" id="Symbolic">Symbolic</span></h3>
    <p>When access to digital computers became possible in the mid-1950s, AI research began to explore the possibility that human intelligence could be reduced to symbol manipulation. The research was centered in three institutions: <a href="/wiki/Carnegie_Mellon_University" title="Carnegie Mellon University">Carnegie Mellon University</a>, <a href="/wiki/Stanford" class="mw-redirect" title="Stanford">Stanford</a>, and <a href="/wiki/MIT" class="mw-redirect" title="MIT">MIT</a>, and as described below, each one developed its own style of research. <a href="/wiki/John_Haugeland" title="John Haugeland">John Haugeland</a> named these symbolic approaches to AI "good old fashioned AI" or "<a href="/wiki/GOFAI" class="mw-redirect" title="GOFAI">GOFAI</a>".<sup id="cite_ref-GOFAI_174-0" class="reference"><a href="#cite_note-GOFAI-174">[168]</a></sup> During the 1960s, symbolic approaches had achieved great success at simulating high-level "thinking" in small demonstration programs. Approaches based on <a href="/wiki/Cybernetics" title="Cybernetics">cybernetics</a> or <a href="/wiki/Artificial_neural_network" title="Artificial neural network">artificial neural networks</a> were abandoned or pushed into the background.<sup id="cite_ref-175" class="reference"><a href="#cite_note-175">[g]</a></sup>
        Researchers in the 1960s and the 1970s were convinced that symbolic approaches would eventually succeed in creating a machine with <a href="/wiki/Artificial_general_intelligence" title="Artificial general intelligence">artificial general intelligence</a> and considered this the goal of their field.
        </p>
        <h4><span class="mw-headline" id="Cognitive_simulation">Cognitive simulation</span></h4>
        <p>Economist <a href="/wiki/Herbert_A._Simon" title="Herbert A. Simon">Herbert Simon</a> and <a href="/wiki/Allen_Newell" title="Allen Newell">Allen Newell</a> studied human problem-solving skills and attempted to formalize them, and their work laid the foundations of the field of artificial intelligence, as well as <a href="/wiki/Cognitive_science" title="Cognitive science">cognitive science</a>, <a href="/wiki/Operations_research" title="Operations research">operations research</a> and <a href="/wiki/Management_science" title="Management science">management science</a>. Their research team used the results of <a href="/wiki/Psychology" title="Psychology">psychological</a> experiments to develop programs that simulated the techniques that people used to solve problems. This tradition, centered at <a href="/wiki/Carnegie_Mellon_University" title="Carnegie Mellon University">Carnegie Mellon University</a> would eventually culminate in the development of the <a href="/wiki/Soar_(cognitive_architecture)" title="Soar (cognitive architecture)">Soar</a> architecture in the middle 1980s.<sup id="cite_ref-AI_at_CMU_in_the_60s_176-0" class="reference"><a href="#cite_note-AI_at_CMU_in_the_60s-176">[169]</a></sup><sup id="cite_ref-Soar_177-0" class="reference"><a href="#cite_note-Soar-177">[170]</a></sup>
        </p>

    </body>
</html>